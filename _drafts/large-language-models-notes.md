---
title:  "LLMs: Notes"
description: Notes about Large Language Models
date: 2023-06-10 14:00:00
layout: post
---

Course: https://web.stanford.edu/class/cs25/index.html#course
Playlist:https://youtube.com/playlist?list=PLJSBz7tS33ykhtE1h8WTqIXunyAFfWNaO

LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale - https://arxiv.org/abs/2208.07339
8-bit Optimizers via Block-wise Quantization - https://arxiv.org/abs/2110.02861
LoRA: Low-Rank Adaptation of Large Language Models - https://arxiv.org/abs/2106.09685
QLoRA: Efficient Finetuning of Quantized LLMs - https://arxiv.org/abs/2305.14314
SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression - https://arxiv.org/abs/2306.03078
Transformer Inference Arithmetic - https://kipp.ly/blog/transformer-inference-arithmetic/
Efficient GEMM in CUDA - https://github.com/NVIDIA/cutlass/blob/main/media/docs/efficient_gemm.md
